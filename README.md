# ğŸ§  Real-Time Webcam-Based Eye Gaze Control System  
**With Intelligent Blink Recognition for Assistive Computing**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.5.3-green.svg)](https://opencv.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Contributions Welcome](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)](CONTRIBUTING.md)
[![Code of Conduct](https://img.shields.io/badge/Code%20of%20Conduct-Active-blue.svg)](CODE_OF_CONDUCT.md)
[![Security Policy](https://img.shields.io/badge/Security-Policy-orange.svg)](SECURITY.md)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)]()

>
[![Contributions Welcome](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)](CONTRIBUTING.md)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
 âš™ï¸ An accessible, low-cost **eye-gaze control system** using standard webcams â€” featuring **real-time tracking** and **intelligent blink-based control** for users with motor impairments.

---

## ğŸ“„ Research Paper

**Real-Time Webcam-Based Eye Gaze Control System with Intelligent Blink Recognition for Assistive Computing**

**Authors:**  
K. Ujjwal Reddy, Karthik M, P. V. Koushik Reddy  
**Affiliation:** Sir M Visvesvaraya Institute of Technology, Bengaluru, India  

ğŸ“˜ *Published in:* [Conference Name], [Year]  
ğŸ”— *Link:* _Coming soon_

---

## ğŸ¯ Overview

This project enables **hands-free computer control** through real-time **eye and blink tracking**, requiring only a standard webcam â€” no infrared cameras, depth sensors, or GPUs needed.

### âœ¨ Key Highlights
- ğŸ§© **Multi-Algorithm Pupil Fusion** (Intensity + Hough + Contour)
- ğŸ‘ï¸ **Adaptive Blink Recognition FSM** with 94.2% accuracy  
- âš¡ **Real-Time Operation:** 26.7 FPS on Intel i5 hardware  
- ğŸ”§ **Configurable:** 50+ parameters for calibration and control  
- ğŸ’» **Cross-Platform:** Works on Windows, Linux, and macOS  

---

## ğŸ“Š Performance Summary

| Metric | Value |
|--------|-------|
| Mean Positioning Error | 62 px |
| Click Detection Accuracy | 94.2% |
| False Positives | 0.3 / min |
| Frame Rate | 26.7 FPS |
| CPU Usage | < 60% |

---

## ğŸš€ Quick Start

### âœ… Requirements
- Python 3.9+
- Webcam (720p minimum, 1080p recommended)
- 4 GB+ RAM  
- Windows/macOS/Linux

### ğŸ”§ Installation

```bash
# Clone the repository
git clone https://github.com/<your-username>/eye-gaze-assistive-control.git
cd eye-gaze-assistive-control

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate     # On Windows
# source venv/bin/activate  # On Linux/macOS

# Install dependencies
pip install -r requirements.txt

# Download pre-trained models
python download_models.py
```

---

## â–¶ï¸ Usage

### 1ï¸âƒ£ Calibration
```bash
python main.py --calibrate
```
Follow the on-screen 9-point calibration and blink tests.  

### 2ï¸âƒ£ Normal Operation
```bash
python main.py
```
**Controls:**
- ğŸ‘ï¸ Look â†’ Move cursor  
- ğŸ‘ Left blink â†’ Left click  
- ğŸ‘ Right blink â†’ Right click  
- ğŸ‘ğŸ‘ Double blink â†’ Double-click  
- ğŸ‘ Dwell gaze (2s) â†’ Auto click  

---

## âš™ï¸ Configuration

Edit `config/config.yaml` for fine-tuning:

```yaml
# Gaze tracking
sensitivity: 1.5
smoothing_alpha: 0.3
nonlinearity_gamma: 1.15

# Blink detection
ear_threshold: 0.25
blink_duration_min: 80
blink_duration_max: 400
cooldown_period: 150

# Camera
resolution: [640, 480]
fps: 30
```

Full details: [`docs/configuration.md`](docs/configuration.md)

---

## ğŸ§© System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam    â”‚ 640Ã—480 @ 30 FPS
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Face Detection  â”‚ HOG + dlib (12 ms)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Facial Landmarks â”‚ 68-point predictor
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gaze â”‚ â”‚ Blink â”‚
â”‚Track â”‚ â”‚ Detectâ”‚
â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”˜
    â–¼         â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Cursor + â”‚
  â”‚  Clicks  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

More in: [`docs/architecture.md`](docs/architecture.md)

---

## ğŸ”¬ Technical Insights

### ğŸ§  Multi-Algorithm Fusion
Combines:
1. **Intensity-Extrema** â†’ Fast under contrast  
2. **Circular Hough Transform** â†’ Accurate under strong edges  
3. **Contour Analysis** â†’ Robust to occlusion  

Weighted fusion formula:
\[
(x_f, y_f) = \frac{\sum Q_i x_i}{\sum Q_i}, \quad \frac{\sum Q_i y_i}{\sum Q_i}
\]

### ğŸ‘ï¸ Blink FSM
- Duration: 80â€“400 ms  
- EAR Drop â‰¥ 25%  
- Cooldown: 150 ms  
â†’ Reduces false positives by **67%**

---

## ğŸ§ª Evaluation Results

| Method | Mean Error | Variance | Failure Rate |
|--------|------------|-----------|---------------|
| Intensity-only | 89 Â± 34 px | 1156 | 12.0% |
| Hough-only | 76 Â± 28 px | 784 | 8.0% |
| Contour-only | 82 Â± 31 px | 961 | 10.0% |
| Fixed-weight | 71 Â± 26 px | 676 | 5.0% |
| **Ours (Quality-weighted)** | **62 Â± 18 px** | **324** | **2.0%** |

---

## ğŸ—ï¸ Project Structure

```
Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing/
â”œâ”€â”€ enhanced_main.py                  # Main entry point
â”œâ”€â”€ enhanced_eye_tracker.py           # Eye and gaze tracking module
â”œâ”€â”€ enhanced_blink_detector.py        # Blink recognition logic
â”œâ”€â”€ enhanced_config.py                # Configuration parameters
â”œâ”€â”€ enhanced_utils.py                 # Utility functions
â”œâ”€â”€ true_gaze_tracker.py              # Advanced gaze estimation logic
â”œâ”€â”€ shape_predictor_68_face_landmarks.dat  # Dlib facial landmark model
â”œâ”€â”€ Setup_and_Test.py                 # Environment setup and test script
â”œâ”€â”€ README.md                         # Documentation
â”œâ”€â”€ LICENSE                           # MIT License
â”œâ”€â”€ CONTRIBUTING.md                   # Contribution guide
â”œâ”€â”€ CODE_OF_CONDUCT.md                # Community guidelines
â”œâ”€â”€ SECURITY.md                       # Security reporting policy
â”œâ”€â”€ .gitignore                        # Ignored files for Git
â””â”€â”€ __pycache__/                      # Python bytecode cache
```

eye-gaze-assistive-control/
â”œâ”€â”€ main.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gaze_tracker.py
â”‚   â”œâ”€â”€ blink_detector.py
â”‚   â”œâ”€â”€ pupil_fusion.py
â”‚   â”œâ”€â”€ calibration.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ default.yaml
â”‚   â””â”€â”€ profiles/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ shape_predictor_68_face_landmarks.dat
â”œâ”€â”€ docs/
â”œâ”€â”€ tests/
â””â”€â”€ requirements.txt
```

---

## ğŸ³ Docker Deployment

```bash
docker build -t eye-gaze-control .
docker run --device=/dev/video0 -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix eye-gaze-control
```

---

## ğŸ¤ Contributing

We welcome contributions in:
- New pupil detection algorithms  
- Calibration-free gaze estimation  
- 3D head pose correction  
- Performance benchmarking  

**Steps:**
1. Fork this repo  
2. Create branch â†’ `feature/my-feature`  
3. Commit â†’ `git commit -m "Add my feature"`  
4. Push â†’ `git push origin feature/my-feature`  
5. Open a Pull Request  

See [`CONTRIBUTING.md`](CONTRIBUTING.md)

---

## ğŸ“œ License

Licensed under **MIT License** â€” see [`LICENSE`](LICENSE).  
> ğŸª¶ Open, accessible, and free for both academic and commercial use.

---

## ğŸ“š Citation

```bibtex
@inproceedings{reddy2024eyegaze,
  title={Real-Time Webcam-Based Eye Gaze Control System with Intelligent Blink Recognition for Assistive Computing},
  author={Reddy, K. Ujjwal and M, Karthik and Reddy, P. V. Koushik},
  booktitle={Proceedings of [Conference Name]},
  year={2024},
  organization={IEEE}
}
```

---

## ğŸ™ Acknowledgments
- Sir M Visvesvaraya Institute of Technology â€“ AI/ML Department  
- OpenCV & dlib open-source communities  
- All study participants for their valuable feedback  

---

## âš ï¸ Disclaimer
This system is a **research prototype** for assistive technology.  
Not certified for clinical or medical use. Please test carefully before deploying in accessibility-critical contexts.

---

## ğŸ—ºï¸ Roadmap
- [x] v1.0 â€“ Initial release  
- [ ] v1.1 â€“ Add MobileNet-based CNN detector  
- [ ] v1.2 â€“ 3D head-pose correction  
- [ ] v2.0 â€“ Calibration-free gaze mapping  
- [ ] v2.1 â€“ Multi-modal fusion (voice + gaze + gesture)  

---

## ğŸ“ˆ GitHub Stats

[![GitHub Stars](https://img.shields.io/github/stars/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing?style=social)](https://github.com/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing?style=social)](https://github.com/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing/network/members)
[![GitHub Issues](https://img.shields.io/github/issues/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing)](https://github.com/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing)](https://github.com/Ujjwalreddy16/Eye-Gaze-Control-System-with-Intelligent-Blink-Recognition-for-Assistive-Computing/pulls)

---

**ğŸ’¡ Made with passion for accessibility â€” empowering users through vision-based computing.**


